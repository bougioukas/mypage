{
  "hash": "7b2ac398eabba56f6b4260d93ce8889d",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Two-sample permutation test: How it works\"\ndescription: \"Permutation tests approximate the null distribution of a test statistic by repeatedly resampling the data in a way that is consistent with the null hypothesis.\"\nauthor: \n    - name: Konstantinos Bougioukas \ndate: \"2025-12-15\"\ncategories: [Statistics]\nimage: \"permtest.png\"\ncss: /custom.css\n#draft: true\n---\n\n\n\n​\n\n## Permutation Tests\n\nPermutation tests, also known as randomization or re-randomization tests, approximate the null distribution of a test statistic by resampling in a manner consistent with the null hypothesis, a concept originating in Fisher’s early work on randomized experiments. They are especially useful when parametric assumptions, such as normality, are questionable or when sample sizes are small.\n\n### Two-sample problem\n\nThe two-sample permutation test uses this resampling approach to assess whether the locations of two independent groups differ, providing a non-parametric alternative to traditional tests of mean or median differences.\n\nThis is achieved by repeatedly permuting the data labels without replacement—so that each permutation is a rearrangement of the original labels—and recalculating the test statistic for each permutation. The resulting p-value is the proportion of permutations that produce a statistic as extreme as—or more extreme than—the observed value.\n\nWe now describe this framework in detail, step by step.\n\nLet $\\mathbf{X_1} = \\{X_{1i}, i = 1, 2, ..., n_1  \\}$ and $\\mathbf{X_2} = \\{X_{2i}, i = 1, 2, ..., n_2  \\}$ be two sets of independent sample data. The objective is to test whether the data are consistent with the null hypothesis of no difference in locations of the distributions ($\\delta = 0$, where $\\delta$ is known as the treatment effect)\n\n$$H_o: \\mathbf{X_1} \\stackrel{d}{=} \\mathbf{X_2}$$\n\nor with the two-sided alternative ($\\delta \\neq 0$)\n\n$$H_1: \\mathbf{X_1} \\stackrel{d}{\\neq} \\mathbf{X_2}$$\n\n**Step 1: Combine the two datasets**\n\nFirst, we combine the two datasets in one vector as follows:\n\n$$\\mathbf{X} = \\mathbf{X}_1 \\uplus \\mathbf{X}_2 = \\{X_i, i = 1, \\ldots, n\\}, \\ \\ \\ n= n_1 + n_2$$\n\nwhere $\\uplus$ denotes concatenation, so that the two samples are pooled into a single set $\\mathbf{X}$, which is fixed.\n\n​\n\n**Step 2: Create an assignment indicator vector**\n\nThe assignment vector $\\mathbf{Z}$ indicates which group each participant belongs to:\n\n$$\\mathbf{Z} = \\{{Z_i, i = 1, \\ldots, n}\\}$$\n\nwhere:\n\n$$\nZ_i = \n\\begin{cases}\n1, & \\text{if participant } i \\text{ is assigned to } \\mathbf{X}_1,\\\\\n0, & \\text{if participant } i \\text{ is assigned to } \\mathbf{X}_2.\n\\end{cases}\n$$\n\nProperties of $\\mathbf{Z}$:\n\n-   Each $Z_i$ is binary: $Z_i \\in \\{0, 1\\}$\n\n-   The sum $\\sum_{i=1}^{n} Z_i = n_1$ (counts how many are in Group 1)\n\n-   The sum $\\sum_{i=1}^{n} (1 - Z_i) = n_2$ (counts how many are in Group 2)\n\n​\n\nTherefore, the observed assignment indicator is:\n\n$$\n\\mathbf{Z^{\\text{obs}}} = (\\underbrace{1, 1, \\ldots, 1}_{n_1 \\text{ times}}, \\underbrace{0, 0, \\ldots, 0}_{n_2 \\text{ times}})\n$$\n\n​\n\n**Step 3: Define the test statistic (e.g., difference in means)**\n\nThe test statistic is a function of both $\\mathbf{Z}$ and $\\mathbf{X}$:\n\n$$T (\\mathbf{Z}, \\mathbf{X}) = \\mathbf{\\bar{X}_1} - \\mathbf{\\bar{X}_2}$$\n\nwhere the group means are\n\n$$\\mathbf{\\bar{X}_1} = \\frac{1}{n_1} \\sum_{i=1}^{n} Z_i X_i = \\frac{1}{n_1} \\sum_{i: Z_i = 1} X_i$$\n\n$$\\mathbf{\\bar{X}_2} = \\frac{1}{n_2} \\sum_{i=1}^{n} (1 - Z_i) X_i = \\frac{1}{n_2} \\sum_{i: Z_i = 0} X_i$$\n\nTherefore, the observed test statistic is:\n\n$$T^{obs}=T(\\mathbf{Z^{obs}},\\mathbf{X})$$\n\n​\n\n**Step 4: Generate the permutation distribution**\n\nUnder the null hypothesis $H_o$, any permutation of $\\mathbf{Z}$ is just as likely to have produced the observed data $\\mathbf{X}$ as the actual assignment $\\mathbf{Z^{obs}}$. Relying on this assumption, we randomly permute (suffle) the group labels while keeping the data values fixed. For each permutation, we recalculate the test statistic $T$.\n\nIf we consider all possible orderings of n observations:\n\n$$n! = n \\times (n-1) \\times (n-2) \\times \\cdots \\times 2 \\times 1$$\n\nthen, for example, if $n=16$, the total number of orderings (i.e., permutations of all 16 items) is enormous:\n\n$$16! \\approx 2.09 \\times 10^{13}$$\n\nHowever, for a test statistic based on group means, we are only interested in which observations belong to which group—not the order of observations within each group. The mean of a set of numbers remains the same no matter the order in which the numbers are added.\n\nIn this case, we only need to determine which observations go into the first group; the remaining observations automatically belong to the second group. The number of such distinct assignments (cardinality) is :\n\n$$M = \\ ^nC_{n_1} = \\binom{n}{n_1} = \\frac{n!}{n_1! \\, (n - n_1)!}$$ This represents choosing $n_1$ observations out of $n$ to be in Group 1. The remaining $n_2 = n - n_1$ observations then automatically form Group 2.\n\n::: callout-note\n# A simple example\n\nLet's consider a total of $n=4$ observations that are to be split into two groups: Group A with $n_1=2$ observations and Group B with $n_2=2$ observations. The pooled data set, $\\mathbf{X}$, is fixed as the set of values $\\{a_1, a_2, b_1, b_2\\}$.\n\nAssuming the specific numerical observations are $\\{1, 2, 3, 4\\}$, the possible permutations for splitting this data set into two groups of size two are:\n\n-   $A = \\{1, 2\\} | B = \\{3, 4\\}$\n-   $A = \\{1, 3\\} | B = \\{2, 4\\}$\n-   $A = \\{1, 4\\} | B = \\{2, 3\\}$\n-   $A = \\{2, 3\\} | B = \\{1, 4\\}$\n-   $A = \\{2, 4\\} | B = \\{1, 3\\}$\n-   $A = \\{3, 4\\} | B = \\{1, 2\\}$\n\n$$M = \\ ^4C_2 = \\binom{4}{2} = \\frac{4!}{2!(4-2)!} = \\frac{4 \\times 3 \\times 2 \\times 1}{(2 \\times 1)(2 \\times 1)} = \\frac{24}{4} = 6$$\n:::\n\n​\n\nThe set of all possible assignment vectors:\n\n$$\\Omega = \\Big\\{ \\mathbf{Z}^{(m)} : \\sum_{i=1}^{n} Z_i^{(m)} = n_1, \\ Z_i^{(m)} \\in \\{0,1\\}, \\ m = 1, \\dots, M \\Big\\}$$ For each $\\mathbf{Z}^{(m)} \\in \\Omega$, we compute:\n\n$$T^{(m)} = T(\\mathbf{Z}^{(m)}, \\mathbf{X})$$\n\nThis gives us the exact permutation distribution:\n\n$$\\mathcal{T} = \\{ T^{(1)}, T^{(2)}, \\dots, T^{(M)} \\}$$\n\n​\n\n**Step 5: Calculate the p-value**\n\nFor a two-sided exact p-value:\n\n$$\np\n=\n\\begin{cases}\n\\displaystyle\n\\frac{1}{M}\n\\sum_{m=1}^{M}\n\\Big[\n\\mathbf{I}\\!\\left(T^{(m)} \\ge T^{\\text{obs}}\\right)\n+\n\\mathbf{I}\\!\\left(T^{(m)} \\le -T^{\\text{obs}}\\right)\n\\Big],\n& if \\ \\ T^{\\text{obs}} > 0,\n\\\\[1.2em]\n\\displaystyle\n\\frac{1}{M}\n\\sum_{m=1}^{M}\n\\Big[\n\\mathbf{I}\\!\\left(T^{(m)} \\le T^{\\text{obs}}\\right)\n+\n\\mathbf{I}\\!\\left(T^{(m)} \\ge -T^{\\text{obs}}\\right)\n\\Big],\n& if \\ \\ T^{\\text{obs}} < 0.\n\\end{cases}\n$$\n\nor more compactly\n\n$$\np\n=\n\\frac{1}{M}\n\\sum_{m=1}^{M}\n\\mathbf{I}\\!\\left(\n\\left|T^{(m)}\\right|\n\\ge\n\\left|T^{\\text{obs}}\\right|\n\\right)\n$$\n\nwhere the indicator function $\\mathbf{I}(\\text{condition}) =\n\\begin{cases}\n1, & \\text{if condition is true},\\\\\n0, & \\text{otherwise}.\n\\end{cases}$\n\n### Monte Carlo simulation\n\nWhen $M$ is large (computationally unfeasible to enumerate all permutations), we use Monte Carlo simulation. In this case, we generate random permutation $Z^{(b)}$ and compute the test statistic on the permuted labels $T^{(b)} = T(\\mathbf{Z}^{(b)}, \\mathbf{X}), \\ where \\ b = 1, \\dots, B$ and $B$ is the number of Monte Carlo permutations. This creates the approximate permutation distribution $\\mathcal{T_{aprox}} = \\{T^{(1)}, T^{(2)}, \\ldots, T^{(B)}\\}$ and the p-value is calculated as:\n\n$$\n\\hat{p}_{\\text{MC}}\n=\n\\frac{1}{B}\n\\sum_{b=1}^{B}\n\\mathbf{I}\\!\\left(\n\\left|T^{(b)}\\right|\n\\ge\n\\left|T^{\\text{obs}}\\right|\n\\right)\n$$\n\n​\n\n## Numerical example: application of the framework in R\n\nLet the sample data\n\n$$\\mathbf{X}_1 = \\{66, 57, 81, 62, 61, 60, 73, 53\\} \\quad (n_1=8)$$\n\n$$\\mathbf{X}_2 = \\{64, 58, 59, 44, 47, 56, 48, 51\\} \\quad (n_2=8)$$\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Data\nX1 <- c(66, 57, 81, 62, 61, 60, 73, 53)   # (n1=8)\nX2 <- c(64, 58, 59, 44, 47, 56, 48, 51)   # (n2=8)\n```\n:::\n\n\n\n​\n\n**Step 1: Combine the two datasets**\n\nFollowing the permutation test procedure, the two samples are pooled into a single vector $\\mathbf{X}$ of length $n=16$:$$\\mathbf{X} = \\mathbf{X}_1 \\uplus \\mathbf{X}_2 = \\{66, 57, 81, 62, 61, 60, 73, 53, 64, 58, 59, 44, 47, 56, 48, 51\\}$$\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn1 <- length(X1)\nn2 <- length(X2)\nn <- n1 + n2\nX <- c(X1, X2)\nX\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] 66 57 81 62 61 60 73 53 64 58 59 44 47 56 48 51\n```\n\n\n:::\n:::\n\n\n\n​\n\n**Step 2: Create the observed assignment vector**\n\nThe observed assignment vector is:\n\n$$\n\\mathbf{Z^{\\text{obs}}} = (\\underbrace{1, 1, 1, 1, 1, 1, 1, 1}_{8 \\text{ times}}, \\underbrace{0, 0, 0, 0, 0, 0, 0, 0}_{8 \\text{ times}})\n$$\n\nTherefore:\n\n|  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n| $\\mathbf{X}$ | 66 | 57 | 81 | 62 | 61 | 60 | 73 | 53 | 64 | 58 | 59 | 44 | 47 | 56 | 48 | 51 |\n| $\\mathbf{Z^{\\text{obs}}}$ | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n\n​\n\nPermutation $m=1$ (Original Assignment)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Indices for Group 1 (X1) in the pooled vector X\nperm1 <- c(1, 2, 3, 4, 5, 6, 7, 8)\nperm1 \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1 2 3 4 5 6 7 8\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Initialize the assignment vector Z to all zeros\nZ_1 <- numeric(16)\nZ_1\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Assign 1s to the indices corresponding to Group 1\nZ_1[perm1] <- 1    # Put 1s at positions 1-8\nZ_1\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nZ_obs <- Z_1\nZ_obs\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0\n```\n\n\n:::\n:::\n\n\n\n​\n\n**Step 3: Calculate the observed test statistic**\n\nThe $T^{obs}$ statistic is:\n\n$$T^{obs} = T(\\mathbf{Z}^{(obs)}, \\mathbf{X})$$\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nX1_mean <- mean(X1)\nX2_mean <- mean(X2)\nT_obs <- X1_mean - X2_mean\nT_obs\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 10.75\n```\n\n\n:::\n:::\n\n\n\n​\n\n**Step 4: Generate the permutation distribution**\n\nNext, the following two permutations are presented (i.e., m = 2 and m = 3).\n\n-   For permutation $m=2$ (Different Assignment; the last element is changed to 9)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Indices for Group 1 (X1) in the pooled vector X\nperm2 <- c(1, 2, 3, 4, 5, 6, 7, 9)     # now last element is 9\nperm2 \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1 2 3 4 5 6 7 9\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Initialize the assignment vector Z to all zeros\nZ_2 <- numeric(16)\nZ_2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Assign 1s to the indices corresponding to Group 1\nZ_2[perm2] <- 1    # Put 1s at positions 1-7 and 9\nZ_2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] 1 1 1 1 1 1 1 0 1 0 0 0 0 0 0 0\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nX1_perm2 <- X[Z_2 == 1]\nX1_perm2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 66 57 81 62 61 60 73 64\n```\n\n\n:::\n\n```{.r .cell-code}\nX2_perm2 <- X[Z_2 == 0]\nX2_perm2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 53 58 59 44 47 56 48 51\n```\n\n\n:::\n:::\n\n\n\nThe T statistic is:\n\n$$T^{(2)} = T(\\mathbf{Z}^{(2)}, \\mathbf{X})$$\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nT_perm2 <- mean(X1_perm2) - mean(X2_perm2)\nT_perm2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 13.5\n```\n\n\n:::\n:::\n\n\n\n​\n\n-   Similarly, for permutation $m=3$ (Different Assignment; the last element is changed to 10)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Indices for Group 1 (X1) in the pooled vector X\nperm3 <- c(1, 2, 3, 4, 5, 6, 7, 10)    # now the last element is 10\nperm3 \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1]  1  2  3  4  5  6  7 10\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Initialize the assignment vector Z to all zeros\nZ_3 <- numeric(16)\nZ_3\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Assign 1s to the indices corresponding to Group 1\nZ_3[perm3] <- 1    # Put 1s at positions 1-7 and 10\nZ_3\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] 1 1 1 1 1 1 1 0 0 1 0 0 0 0 0 0\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nX1_perm3 <- X[Z_3 == 1]\nX1_perm3\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 66 57 81 62 61 60 73 58\n```\n\n\n:::\n\n```{.r .cell-code}\nX2_perm3 <- X[Z_3 == 0]\nX2_perm3\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 53 64 59 44 47 56 48 51\n```\n\n\n:::\n:::\n\n\n\nThe T statistic is:\n\n$$T^{(3)} = T(\\mathbf{Z}^{(3)}, \\mathbf{X})$$\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nT_perm3 <- mean(X1_perm3) - mean(X2_perm3)\nT_perm3\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 12\n```\n\n\n:::\n:::\n\n\n\n​\n\nNow, the total number of possible permutations is computed as:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nM <- choose(n, n1)\nM\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 12870\n```\n\n\n:::\n:::\n\n\n\nIn this case, it is feasible to generate all possible permutations:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# generate  all possible combinations of choosing n1 elements from the set X\nlibrary(combinat)\nall_perms <- combn(1:n, n1)\n```\n:::\n\n\n\nThe first three permutations, as found previously, are:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nall_perms[, c(1:3)]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     [,1] [,2] [,3]\n[1,]    1    1    1\n[2,]    2    2    2\n[3,]    3    3    3\n[4,]    4    4    4\n[5,]    5    5    5\n[6,]    6    6    6\n[7,]    7    7    7\n[8,]    8    9   10\n```\n\n\n:::\n:::\n\n\n\n​\n\nThe collection of all possible T statistics—one for each possible way to divide the $n$ observations into groups of size $n_1$, $\\mathcal{T} = \\{ T^{(1)}, T^{(2)}, \\dots, T^{(12870)} \\}$, can be generated using the following loop:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nT_perm <- numeric(M)\n\nfor (m in 1:M) {\n  # Create assignment vector for this permutation\n  Z_m <- numeric(n)\n  Z_m[all_perms[, m]] <- 1\n  \n  # Calculate test statistic for this permutation\n  X1_perm <- X[Z_m == 1]\n  X2_perm <- X[Z_m == 0]\n  T_perm[m] <- mean(X1_perm) - mean(X2_perm)\n}\n```\n:::\n\n\n\nWe can print the first three T static values as follows (we have computed them previously):\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nT_perm[1:3]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 10.75 13.50 12.00\n```\n\n\n:::\n:::\n\n\n\n​\n\nFinally, we create the histogram of the computed T statistics that is the exact permutation distribution. Each bar represents the number of times a particular range of $T$ values occurs across all possible permutations of the data.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhist(T_perm, breaks = 50, col = rgb(0.8, 1, 0.8), \n     main = \"Exact Permutation Distribution\",\n     xlab = \"Test Statistic T\", xlim = c(-15, 15))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n:::\n\n\n\n**Step 5: Calculate the p-value**\n\nSince the $T^{obs} = 10.75 > 0$:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\np_value_exact <- (sum(T_perm >= T_obs) + sum(T_perm <= -T_obs)) / M\np_value_exact\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.01787102\n```\n\n\n:::\n:::\n\n\n\n​\n\nThe extreme values of T statistic, which are unlikely under the null hypothesis, are highlighted in a light red color. The upper tail corresponds to $T \\ge T^{\\text{obs}}$, and the lower tail corresponds to $T \\le -T^{\\text{obs}}$.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Histogram of permutation distribution with colored tails\nh <- hist(T_perm, breaks = 50, plot = FALSE)\ncolors <- ifelse(h$mids >= T_obs | h$mids <= -T_obs, \n                 rgb(1, 0, 0, 0.5), rgb(0.8, 1, 0.8))\n\nplot(h, col = colors, main = \"Exact Permutation Distribution\",\n     xlab = \"Test Statistic T\", xlim = c(-15, 15))\nabline(v = T_obs, col = \"darkred\", lwd = 2, lty = 2)\ntext(T_obs, max(h$counts) * 0.95,\n     bquote(T^{obs} == .(round(T_obs, 2))),\n     col = \"darkred\", cex = 1, font = 2, adj = c(0.5, 0))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-25-1.png){width=672}\n:::\n:::\n\n\n\nor equivalently\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\np_value_exact <- mean(abs(T_perm) >= abs(T_obs))\np_value_exact\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.01787102\n```\n\n\n:::\n:::\n\n\n\nThe corresponding p-value is $p = 0.0179$. Since $p < 0.05$, the observed test statistic lies in the extreme tails of the permutation distribution, indicating that the observed grouping is unusual under the null hypothesis. Therefore, we reject the null hypothesis at the 5% significance level, suggesting a statistically significant difference between the groups.\n\n​\n\nThe result can also be confirmed by using the **`oneway_test()`** function from the ***coin*** R package: \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncoin::oneway_test(X~factor(Z_obs), distribution=\"exact\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tExact Two-Sample Fisher-Pitman Permutation Test\n\ndata:  X by factor(Z_obs) (0, 1)\nZ = -2.2489, p-value = 0.01787\nalternative hypothesis: true mu is not equal to 0\n```\n\n\n:::\n:::\n\n\n\n​\n\n## Comparison to the classic two-sample T-test\n\nLet's formally apply the two-sample t-test to compare its p-value with that of the permutation test.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(X1, X2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tWelch Two Sample t-test\n\ndata:  X1 and X2\nt = 2.6686, df = 13.108, p-value = 0.0192\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n  2.054571 19.445429\nsample estimates:\nmean of x mean of y \n   64.125    53.375 \n```\n\n\n:::\n:::\n\n\n\nIn this example, the results are highly consistent. Both the exact Permutation Test ($p = 0.0179$) and the two-sample T-test ($p = 0.0192$) yield close p-values.\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}