{
  "hash": "296e2fb3b506f437cae3a67f83397890",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Perceptron: the first artificial neuron\"\ndescription: \"The perceptron is one of the earliest and simplest models of an artificial neuron, introduced by Frank Rosenblatt in 1957 as a computational approach inspired by biological neurons.\"\nauthor: \n    - name: Konstantinos Bougioukas \ndate: \"2026-01-03\"\ncategories: [Statistics]\nimage: \"perceptron.png\"\ncss: /custom.css\n#draft: true\n---\n\n\n\n​\n\n## The perceptron\n\nThe perceptron is one of the earliest and simplest models of an artificial neural network. Conceptually, it corresponds to a single artificial neuron that makes binary decisions. Despite its simplicity, the perceptron introduced the core ideas of weighted inputs, linear decision boundaries, and supervised learning for classification tasks—ideas that remain central to modern deep learning.\n\nAt its heart, the perceptron learns to separate data into two classes by finding a linear boundary that divides the input space. Each prediction is obtained by combining the inputs linearly and passing the result through a threshold function that produces a discrete output.\n\n\n\n### How it works\n\nThe *Perceptron* can be viewed as a simple directed graph, with edges connecting each input to the output and parameterized by weights. The output of the perceptron depends both on the values of the input nodes and on the weights associated with the incoming edges, which control how strongly each input influences the final decision.\n\n\n![Schematic of a simple Perceptron model.](perceptron.png){width=50%}\n\n​\n\n\n### Basic set up and notation\n\nThe *Perceptron* takes multiple input features, multiplies each by an associated weight, sums these weighted inputs along with a bias term, and then applies a threshold decision (activation) function to determine the output class. This process can be described compactly using vector notation.\n\nSuppose our dataset consists of $P$ input-output pairs \n\n$$(\\mathbf{x_1}, y_1), (\\mathbf{x_2}, y_2), ..., (\\mathbf{x_P}, y_P)$$ \n\nor equivalently, \n\n\n$$\\left\\{ \\left(\\mathbf{x}_{p},y_{p}\\right)\\right\\} _{p=1}^{P}$$\n\nwhere $\\mathbf{x_p}$ and $y_p$ denote the input and output of the $p-$observation, respectively.\n\nEach input $\\mathbf{x_p}$ is a column vector of length $N +1$, where the leading component is fixed to 1 in order to incorporate the bias term directly into the model: \n\n$$\\mathbf{x_p} = \\begin{bmatrix} 1 \\\\ x_{1,\\ p} \\\\ x_{2,\\ p} \\\\\\vdots \\\\ x_{N,\\ P} \\end{bmatrix}$$\n\nThe model parameters—the bias and feature weights—are collected into a single column vector:\n\n$$\\mathbf{w} = \\begin{bmatrix} w_0 \\\\ w_1 \\\\ w_2 \\\\ \\vdots \\\\ w_N \\end{bmatrix}$$\n\n\nThe target labels are represented by a vector $\\mathbf{y}$ of length $P$ : \n\n$$\\mathbf{y} = \\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_P \\end{bmatrix}$$\n\n\n### Linear Combination\n\nFor a single observation $p$, the perceptron computes a net input $z_p$ by taking the dot product of the weight vector and the input vector:\n\n\n$$z_p = \\mathbf{w}^{\\mathsf{T}}\\mathbf{x}_p$$\n\nwhere the superscript $\\mathsf{T}$ denotes transposition.\n\n\nExpanding this expression makes the computation explicit:\n\n$$\\begin{aligned}\nz_p &= \\begin{bmatrix} w_0 & w_1 & \\cdots & w_N \\end{bmatrix} \\begin{bmatrix} 1 \\\\ x_{1,\\ p} \\\\ x_{2,\\ p} \\\\\\vdots \\\\ x_{N,\\ P} \\end{bmatrix} \\\\\n&= (w_0 \\cdot 1) + (w_1 \\cdot x_{1,p}) + \\dots + (w_N \\cdot x_{N,P})  \\\\\n&= \\underbrace{\\enspace w_0 \\enspace}_{\\text{bias}} + \\underbrace{\\sum_{n=1}^{N} w_{n} \\cdot x_{n, p}}_{\\text{sum of weights}}\n\\end{aligned}$$\n\n\nThus, the net input is simply a **weighted sum** of the input features plus a bias term.\n\n​\n\nComputing this quantity for all P observations yields the vector $\\mathbf{z}$ with p-elements: \n\n$$\\mathbf{z}= \\begin{bmatrix} z_1 \\\\ z_2 \\\\ \\vdots \\\\ z_P \\end{bmatrix}$$\n\n​\n\n\n### Activation function and model prediction\n\nIn the classic perceptron, the **activation function** $f(\\cdot)$ is a step function, which maps the continuous net input to one of two discrete class labels. A common choice is the **sign function**, which assigns a label based on whether the net input is non-negative or negative.\n\n\nThe prediction vector $\\mathbf{\\hat{y}}$ is obtained by applying the activation function element-wise to $\\mathbf{z}$:\n\n$$\\mathbf{\\hat{y}} = \\text{sign}(\\mathbf{z})$$\n\nIn expanded form, this becomes\n\n$$\\begin{bmatrix} \\hat{y}_1 \\\\ \\hat{y}_2 \\\\ \\vdots \\\\ \\hat{y}_P \\end{bmatrix} = \\begin{bmatrix} \\text{sign}(z_1) \\\\ \\text{sign}(z_2) \\\\ \\vdots \\\\ \\text{sign}(z_P) \\end{bmatrix}$$\n\n\nEach individual prediction $\\hat y_p$ is defined as\n\n$$\\hat y_p = \\text{sign}(z_p) = \\begin{cases} 1 & \\text{if } z_p \\ge 0 \\\\ -1 & \\text{if } z_p < 0 \\end{cases}$$\n\nThrough this simple rule, the perceptron partitions the input space into two regions separated by a linear decision boundary, classifying inputs on one side as $+1$ and those on the other side as $-1$, which is why it is considered a linear binary classifier; this decision boundary is defined as the set of points of the input space where the model’s net input is exactly zero, that is, $\\mathbf{x}_p^{\\mathsf{T}}\\mathbf{w} = 0$.\n\n​\n\n### The Weight Update Rule\n\nThe perceptron learns by iteratively adjusting its weights to reduce classification errors. Let $\\mathbf{w}^{\\text{old}}$ be the weight vector before the update, and $\\mathbf{w}^{\\text{new}}$ be the weight vector after the update. The learning rule is expressed as:\n\n$$\\mathbf{w}^{\\text{new}} = \\mathbf{w}^{\\text{old}} + \\eta \\, (y_p - \\hat{y}_p) \\, \\mathbf{x}_p$$\n\nwhere $\\eta > 0$ is the learning rate, controlling the step size of each update. The error term $(y_p - \\hat{y}_p)$ is a discrete scalar that determines the nature of the weight update.\n\n\nThe perceptron learning rule adjusts the weight vector in the direction that reduces the error for the specific example $p$:\n\n- **Correct prediction** ($y_p = \\hat{y}_p$): Since $(y_p - \\hat{y}_p) = 0$, the update term is zero. No change is made, as the model’s current boundary already correctly classifies the point.\n\n- **Incorrect prediction** ($y_p \\neq \\hat{y}_p$): The term $(y_p - \\hat{y}_p)$ becomes either $+2$ or $-2$. The weights are \"nudged\" in the direction of $y_p \\mathbf{x}_p$, moving the decision boundary.\n\n​\n\n### Convergence and separability\n\nTraining proceeds in **epochs**, where each epoch corresponds to a complete pass through the training dataset. Because the perceptron updates its weights incrementally after each individual example, learning typically requires multiple epochs as the decision boundary is gradually adjusted to better separate the data. Whether this process eventually halts—reaching a state known as **convergence**—depends entirely on the linear separability of the training set.\n\nWhen the classes are **linearly separable**, meaning they can be perfectly divided by a straight line in two dimensions or a hyperplane in higher dimensions, the Perceptron Convergence Theorem guarantees that the algorithm will reach a finite weight vector that correctly classifies all training examples. At this point, the weights stabilize and no further updates occur. Conversely, if the data are not linearly separable, no such solution exists. The perceptron will continue updating its weights indefinitely, repeatedly shifting the decision boundary in an attempt to correct misclassifications. Fixing one misclassified point may cause another to become misclassified, producing oscillatory or “jittering” behavior. In practice, training on **non-separable** data is terminated after a fixed number of epochs to prevent unbounded computation.\n\n​\n\n## Perceptron example with R\n\n\n### Data Preparation\n\nWe'll use the famous Iris dataset, focusing on two species (Versicolor and Virginica) to create a binary classification problem.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# load the packages \nlibrary(tidyverse)\nlibrary(gganimate)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# load the dataset\n\ndata(iris)\ndf <- iris[iris$Species != \"setosa\", ] \ndf$y <- ifelse(df$Species == \"versicolor\", 1, -1)\n```\n:::\n\n\n\n​\n\n### Feature Scaling\n\nStandardization ensures all features have mean = 0 and standard deviation = 1. This helps the Perceptron converge faster and prevents features with larger scales from dominating the learning process.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Feature Scaling\ndf_scaled <- df\ndf_scaled[, 1:4] <- scale(df[, 1:4])\ndf_scaled_final <- df_scaled[, c(\"Sepal.Length\", \"Petal.Length\", \"y\")]\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Shuffle data for stochastic learning\nset.seed(1)\ndf_shuffle <- df_scaled_final[sample(nrow(df_scaled_final)), ]\nX <- as.matrix(df_shuffle[, 1:2])\nX_augmented <- cbind(1, X) # leading 1 for bias\ny_vector <- df_shuffle$y\n```\n:::\n\n\n\nThe augmented matrix includes a column of 1s, which allows us to incorporate the bias term $w_o$ directly into the weight vector.\n\n\n​\n\n### Implement the Perceptron Algorithm\n\n**Sign Activation Function**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsign_func <- function(z) {\n  ifelse(z >= 0, 1, -1)\n}\n```\n:::\n\n\n\n​\n\n**Perceptron Training Function**\n\nThe perceptron algorithm repeatedly cycles through training examples in a randomized order, iteratively adjusting weights only when a misclassification occurs. This process continues until the model achieves convergence (zero errors) or reaches a preset maximum number of epochs. Because the updates are incremental, a single data point may be processed multiple times across different epochs, gradually nudging the decision boundary until it successfully partitions the classes with a valid separating hyperplane.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_perceptron_efficient <- function(X_aug, y, eta = 0.05, n_iter = 10) {\n  n_features <- ncol(X_aug)\n  \n  # Initialize with small random weights (mean 0, sd 0.1)\n  set.seed(42)\n  w <- rnorm(n_features, mean = 0, sd = 0.1) \n  \n  history_list <- list()\n  epoch_errors <- numeric(n_iter)\n  step_total <- 0\n  \n  for (epoch in 1:n_iter) {\n    error_count <- 0\n    for (p in 1:nrow(X_aug)) {\n      step_total <- step_total + 1\n      x_p <- X_aug[p, ]\n      y_p <- y[p]\n      \n      # Linear Combination: z = w^T * x\n      z_p <- as.numeric(t(w) %*% x_p)\n      y_hat <- sign_func(z_p)\n      \n      is_error <- (y_hat != y_p)\n      if (is_error) {\n        # Update Rule from notes\n        w <- w + eta * (y_p - y_hat) * x_p\n        error_count <- error_count + 1\n      }\n      \n      # Calculate current accuracy\n      predictions <- sign_func(X_aug %*% w)\n      current_accuracy <- sum(predictions == y) / length(y) * 100\n      \n      # Record history for every step\n      history_list[[step_total]] <- data.frame(\n        Step = step_total, \n        Epoch = epoch,\n        Iteration = p,\n        w0 = w[1], w1 = w[2], w2 = w[3],\n        x1_val = x_p[2], x2_val = x_p[3],\n        is_error = is_error,\n        current_acc = current_accuracy\n      )\n    }\n    \n    epoch_errors[epoch] <- error_count\n    cat(sprintf(\"Epoch %d: %d errors\\n\", epoch, error_count))\n    \n    # THE BREAK: Stop if the model perfectly separates the data\n    if (error_count == 0) {\n      cat(sprintf(\"--- Converged early at Epoch %d ---\\n\", epoch))\n      break\n    }\n  }\n  \n  return(list(\n    weights = w, \n    errors = epoch_errors[1:epoch], \n    history = do.call(rbind, history_list)\n  ))\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Training\nresults <- fit_perceptron_efficient(X_augmented, y_vector, n_iter = 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nEpoch 1: 12 errors\nEpoch 2: 8 errors\nEpoch 3: 7 errors\nEpoch 4: 6 errors\nEpoch 5: 4 errors\nEpoch 6: 6 errors\nEpoch 7: 4 errors\nEpoch 8: 6 errors\nEpoch 9: 4 errors\nEpoch 10: 6 errors\n```\n\n\n:::\n\n```{.r .cell-code}\nhistory_df <- results$history\nerrors <- results$errors\nw_final <- results$weights\n```\n:::\n\n\n\nThe algorithm is not converging - the errors are oscillating between 4 and 6, never reaching zero. This means the data might not be perfectly linearly separable.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Error Reduction Plot\nplot(1:length(errors), errors, type = \"o\", pch = 16, \n     col = \"blue\", lwd = 2, cex = 1.5,\n     main = \"Learning Curve (Early Stop)\", xlab = \"Epoch\", ylab = \"Errors\")\n```\n\n::: {.cell-output-display}\n![Perceptron learning curve showing error reduction over epochs](index_files/figure-html/unnamed-chunk-8-1.png){width=768}\n:::\n:::\n\n\n\n​\n\n**Animate the Learning Process**\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](perceptron_learning.gif)\n:::\n:::\n\n\n\n\n\nThe decision boundary is the geometric representation of our learned classifier.\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Final decision boundary separating Versicolor and Virginica](index_files/figure-html/unnamed-chunk-11-1.png){width=768}\n:::\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}