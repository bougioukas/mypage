{
  "hash": "23e7b907fb5809f601fb8b24bb0d7bb9",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"The Cross-Lagged Panel Model: A starting point for understanding longitudinal SEM\"\ndescription: \"The cross-lagged panel model (CLPM) is a path analysis model that is typically estimated within the Structural Equation Modeling (SEM) framework for analyzing dynamic associations between variables measured at multiple time points.\"\nauthor: \n    - name: Konstantinos Bougioukas \ndate: \"2026-01-10\"\ncategories: [Statistics]\nimage: \"clpm.png\"\ncss: /custom.css\n#draft: true\n---\n\n\n\n​\n\n## The Cross-Lagged Panel Model\n\nThe Cross-Lagged Panel Model (CLPM) is a type of path analysis within the discrete-time structural equation modeling (SEM) framework used to analyze panel (longitudinal) data where the same variables are measured repeatedly across multiple time points [@Kenny1975]. We will explore the traditional CLPM in this analysis, recognizing that while it has important limitations due to its relative simplicity [@Hamaker2015], it remains a useful starting point for understanding fundamental concepts in longitudinal modeling.\n\n\n### Basic concepts\n\n@fig-clpm shows a model with three time points ($T1$, $T2$, and $T3$), often called **waves**. The squares represent the observed variables, $X$ and $Y$, at each time point. Single-headed arrows indicate **regression effects** (directional effects), and double-headed arrows indicate **correlations** or **(co)variances**.\n\n​\n\n![Schematic of a bivariate CLPM for three waves and two observed variables.](clpm.png){#fig-clpm width=90%}\n\n​\n\nMore specific, a CLPM typically includes:\n\n- The single-headed **horizontal** arrows (labeled $a$ and $b$) represent **autoregressive effects**, also known as **stability paths**. Specifically, paths $a_1$ and $a_2$ indicate how well variable $X$ at one time point predicts its own value at the next wave. Similarly, paths $b_1$ and $b_2$ indicate the longitudinal stability of variable $Y$ over time. Notably, higher coefficients in these paths suggest that the variable is highly stable and doesn't change much between waves.\n\n\n- The single-headed **diagonal** arrows represent the core of the model: the **cross-lagged effects**. Based on the specific configuration of this model, paths $h_1$ and $h_2$ show the influence of $X$ on future changes in $Y$. Conversely, paths $g_1$ and $g_2$ show the influence of $Y$ on future changes in $X$. These pathways make it possible to evaluate the \"directional\" influence between the two variables over time.\n\n- Within-time **correlations**: associations between variables at the same measurement occasion.\n\n\n​\n\n### Direct paths and indirect effects\n\nTo further detail the mechanics of the cross-lagged panel model, the associations between waves can be mathematically expressed through direct paths and indirect effects (mediation paths). These equations illustrate how the variables at a later time point are a function of the variables from the preceding wave.\n\n\n**Direct path equations**\n\n\n$$X_{T2} = (intercept) + a_1\\cdot X_{T1} + g_1 \\cdot Y_{T1}$$\n$$Y_{T2} = (intercept) + b_1\\cdot Y_{T1} + h_1 \\cdot X_{T1}$$\n\n\n$$X_{T3} = (intercept) + a_2\\cdot X_{T2} + g_2 \\cdot Y_{T2}$$\n$$Y_{T3} = (intercept) + b_2\\cdot y_{T2} + h_2 \\cdot X_{T2}$$\n\n\n\n**Indirect effects (Mediation Paths)**\n\n\n\n$$X_{T1} \\Rightarrow X_{T2} \\Rightarrow Y_{T3}: a_1 \\cdot h_2$$\n$$X_{T1} \\Rightarrow Y_{T2} \\Rightarrow Y_{T3}: h_1 \\cdot b_2$$\n\n$$X_{T1} \\Rightarrow Y_{T2} \\Rightarrow X_{T3}: h_1 \\cdot g_2$$\n\n\n\n$$Y_{T1} \\Rightarrow X_{T2} \\Rightarrow X_{T3}: g_1 \\cdot a_2$$\n\n$$Y_{T1} \\Rightarrow Y_{T2} \\Rightarrow X_{T3}: b_1 \\cdot g_2$$\n\n\n$$Y_{T1} \\Rightarrow X_{T2} \\Rightarrow Y_{T3}: g_1 \\cdot h_2$$\n​\n\nAdditionally, the autoregressive indirect effects are:\n\n$$X_{T1} \\Rightarrow X_{T2} \\Rightarrow X_{T3}: a_1 \\cdot a_2$$\n$$Y_{T1} \\Rightarrow Y_{T2} \\Rightarrow Y_{T3}: b_1 \\cdot b_2$$\n\n\n​\n\n## CLPM with R\n\n\n### Data Preparation\n\n**Dataset**\n\nFor this example, we examine the bidirectional association of weight bias internalization (WBIS) with BMI over time. Using a longitudinal design, data were collected from 925 participants across three distinct time points, or waves ($T_1, T_2, \\text{and } T_3$) (@fig-clpm2). WBIS is defined as the internalization of negative stereotypes and beliefs about one’s own body weight.\n\n​\n\n![Schematic of cross-lagged panel model (CLPM) assessing the association of weight bias internalization (WBIS) with Body Mass Index (BMI) over three timepoints.](clpm2.png){#fig-clpm2 width=90%}\n\n​\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load necessary libraries\nlibrary(lavaan)\nlibrary(tidySEM)\nlibrary(ggplot2)\nlibrary(dplyr)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# load the dataset\nlibrary(readr)\ndat <- read_csv(\"WBIS_BMI.csv\")\ndat\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 925 × 6\n   WBIS_T1 WBIS_T2 WBIS_T3 BMI_T1 BMI_T2 BMI_T3\n     <dbl>   <dbl>   <dbl>  <dbl>  <dbl>  <dbl>\n 1    4.09    4.27    3.91   28.0   28.7   28.7\n 2    6       5.82    6.55   20.3   20.3   19.9\n 3    1.82    1.18    1      26.0   24.1   23.1\n 4    6.64    6       6.27   26.5   26.5   26.5\n 5    3.27    4.09    4.27   25.8   26.4   27.1\n 6    2.91    2.27    3.55   24.4   24.0   24.5\n 7    1.82    2.55    2.18   30.8   31.4   31.1\n 8    5.73    5.73    6.18   26.9   25.8   26.3\n 9    5.91    5.91    6.36   38.9   38.4   40.7\n10    4.27    5       4.18   26.6   26.2   25.8\n# ℹ 915 more rows\n```\n\n\n:::\n:::\n\n\n\n​\n\n\n### Cross-Lagged Panel Model\n\n\n**Model syntax**\n\nThe following syntax defines a 3-Wave Cross-Lagged Panel Model (CLPM) to examine the longitudinal association between Weight Bias Internalization (WBIS) and BMI. The code organizes the analysis into three primary dynamics: \n\n1. regressions (denoted by `~`) represent both autoregressive paths, which measure the stability of a variable over time, and cross-lagged paths, which test if one variable predicts subsequent changes in the other.\n\n2. within-wave correlations (denoted by `~~`) account for the shared variance between WBIS and BMI at each time point.\n\n3. indirect effects (using `:=` operator) to estimate longitudinal mediation pathways by calculating whether an initial measurement at Time 1 influences an outcome at Time 3 through a mediation effect at Time 2.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# --- Define the Model ---\n\nmy_model <- '\n  # Regressions (Direct Paths)\n  WBIS_T2 ~ a1*WBIS_T1 + g1*BMI_T1\n  BMI_T2  ~ b1*BMI_T1  + h1*WBIS_T1\n  \n  WBIS_T3 ~ a2*WBIS_T2 + g2*BMI_T2\n  BMI_T3  ~ b2*BMI_T2  + h2*WBIS_T2\n\n  # Covariances (Within-Wave Associations)\n  WBIS_T1 ~~ BMI_T1\n  WBIS_T2 ~~ BMI_T2\n  WBIS_T3 ~~ BMI_T3\n\n  # Indirect Effects\n  wb1_wb2_bm3 := a1 * h2\n  wb1_bm2_bm3 := h1 * b2\n  wb1_bm2_wb3 := h1 * g2\n  \n  bm1_wb2_wb3 := g1 * a2\n  bm1_bm2_wb3 := b1 * g2\n  bm1_wb2_bm3 := g1 * h2\n  \n  wb1_wb2_wb3 := a1 * a2\n  bm1_bm2_bm3 := b1 * b2\n'\n```\n:::\n\n\n\n\n\n​\n\n**sem() function**\n\nThe `sem()` function from the **_lavaan_** package is used to fit the model to the dataset by estimating the associations defined in the model syntax. Within this function, `fixed.x = FALSE` ensures that the Time 1 variables are treated as observed rather than fixed, which is necessary for estimating baseline correlations, and `meanstructure = TRUE` includes intercepts in the estimation to account for the average levels of $WBIS$ and $BMI$ across waves. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# --- Fit the Model ---\nfit <- sem(my_model, data = dat, fixed.x = FALSE, meanstructure = TRUE)\n```\n:::\n\n\n\n​\n\nOnce the model is fitted, the `summary()` function is used to evaluate the results. By including the `standardized = TRUE` argument, the output displays a `Std.all` column containing the standardized coefficients (Beta weights), which are essential for comparing the relative strength of the paths between WBIS and BMI. Additionally, `fit.measures = TRUE` generates the necessary indices (such as CFI, TLI, and RMSEA) required to report the model's overall \"goodness-of-fit\".\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# --- View Results ---\nsummary(fit, standardized = TRUE, fit.measures = TRUE, rsquare = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nlavaan 0.6-20 ended normally after 38 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        23\n\n  Number of observations                           925\n\nModel Test User Model:\n                                                      \n  Test statistic                               108.605\n  Degrees of freedom                                 4\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                              6985.667\n  Degrees of freedom                                15\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.985\n  Tucker-Lewis Index (TLI)                       0.944\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)             -10753.771\n  Loglikelihood unrestricted model (H1)     -10699.468\n                                                      \n  Akaike (AIC)                               21553.541\n  Bayesian (BIC)                             21664.626\n  Sample-size adjusted Bayesian (SABIC)      21591.581\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.168\n  90 Percent confidence interval - lower         0.142\n  90 Percent confidence interval - upper         0.196\n  P-value H_0: RMSEA <= 0.050                    0.000\n  P-value H_0: RMSEA >= 0.080                    1.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.016\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n  WBIS_T2 ~                                                             \n    WBIS_T1   (a1)    0.820    0.018   44.356    0.000    0.820    0.830\n    BMI_T1    (g1)    0.011    0.005    2.477    0.013    0.011    0.046\n  BMI_T2 ~                                                              \n    BMI_T1    (b1)    0.920    0.011   80.578    0.000    0.920    0.931\n    WBIS_T1   (h1)    0.146    0.047    3.142    0.002    0.146    0.036\n  WBIS_T3 ~                                                             \n    WBIS_T2   (a2)    0.846    0.019   45.219    0.000    0.846    0.837\n    BMI_T2    (g2)    0.010    0.005    2.217    0.027    0.010    0.041\n  BMI_T3 ~                                                              \n    BMI_T2    (b2)    0.971    0.011   91.473    0.000    0.971    0.948\n    WBIS_T2   (h2)    0.094    0.043    2.180    0.029    0.094    0.023\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n  WBIS_T1 ~~                                                            \n    BMI_T1            3.568    0.343   10.417    0.000    3.568    0.365\n .WBIS_T2 ~~                                                            \n   .BMI_T2            0.197    0.055    3.586    0.000    0.197    0.119\n .WBIS_T3 ~~                                                            \n   .BMI_T3            0.148    0.050    2.975    0.003    0.148    0.098\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   .WBIS_T2           0.388    0.118    3.301    0.001    0.388    0.254\n   .BMI_T2            1.867    0.296    6.296    0.000    1.867    0.299\n   .WBIS_T3           0.268    0.119    2.251    0.024    0.268    0.174\n   .BMI_T3            0.615    0.276    2.228    0.026    0.615    0.096\n    WBIS_T1           3.356    0.051   65.897    0.000    3.356    2.167\n    BMI_T1           26.836    0.208  129.164    0.000   26.836    4.247\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   .WBIS_T2           0.657    0.031   21.506    0.000    0.657    0.281\n   .BMI_T2            4.175    0.194   21.506    0.000    4.175    0.107\n   .WBIS_T3           0.650    0.030   21.506    0.000    0.650    0.272\n   .BMI_T3            3.491    0.162   21.506    0.000    3.491    0.085\n    WBIS_T1           2.399    0.112   21.506    0.000    2.399    1.000\n    BMI_T1           39.930    1.857   21.506    0.000   39.930    1.000\n\nR-Square:\n                   Estimate\n    WBIS_T2           0.719\n    BMI_T2            0.893\n    WBIS_T3           0.728\n    BMI_T3            0.915\n\nDefined Parameters:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n    wb1_wb2_bm3       0.077    0.036    2.177    0.029    0.077    0.019\n    wb1_bm2_bm3       0.142    0.045    3.140    0.002    0.142    0.034\n    wb1_bm2_wb3       0.001    0.001    1.811    0.070    0.001    0.001\n    bm1_wb2_wb3       0.009    0.004    2.473    0.013    0.009    0.039\n    bm1_bm2_wb3       0.009    0.004    2.216    0.027    0.009    0.038\n    bm1_wb2_bm3       0.001    0.001    1.636    0.102    0.001    0.001\n    wb1_wb2_wb3       0.693    0.022   31.665    0.000    0.693    0.695\n    bm1_bm2_bm3       0.894    0.015   60.464    0.000    0.894    0.882\n```\n\n\n:::\n:::\n\n\n\n\n​\n\n### Understanding the output from lavaan\n\nWhile the **_lavaan_** output is notoriously comprehensive and can be overwhelming at first glance, it is structured logically to provide a complete view of our model’s performance. It is helpful to view the output in three distinct stages: \n\n**The global model fit**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfitMeasures(fit, c(\"cfi\", \"tli\", \"rmsea\", \"srmr\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  cfi   tli rmsea  srmr \n0.985 0.944 0.168 0.016 \n```\n\n\n:::\n:::\n\n\n\n\nAccording to @hu1999, an acceptable fit is achieved when CFI $\\ge$ 0.95 and SRMR $\\le$ 0.08—a guideline known as the combination rule. This recommendation, however, remains a topic of debate, as these cut-offs can be overly restrictive for complex models or those with smaller sample sizes.\n\n​\n\n**Direct path equations**\n\nUsing the `parameterEstimates()` function allows us to extract the direct path parameters of the model.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Pull the estimates\nestimates <- parameterEstimates(fit)\n```\n:::\n\n\n\n​\n\n*The intercepts*\n\nThe following code extracts the intercept for each equation:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# intercepts\nsubset(estimates, op == \"~1\")[, c(\"lhs\", \"est\")]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       lhs    est\n18 WBIS_T2  0.388\n19  BMI_T2  1.867\n20 WBIS_T3  0.268\n21  BMI_T3  0.615\n22 WBIS_T1  3.356\n23  BMI_T1 26.836\n```\n\n\n:::\n:::\n\n\n\n​\n\n*The regression coefficients*\n\nWe obtain the regression coefficients (the $B$ weights) from the unstandardized `est` column:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# regressions\nsubset(estimates, op == \"~\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      lhs op     rhs label   est    se      z pvalue ci.lower ci.upper\n1 WBIS_T2  ~ WBIS_T1    a1 0.820 0.018 44.356  0.000    0.783    0.856\n2 WBIS_T2  ~  BMI_T1    g1 0.011 0.005  2.477  0.013    0.002    0.020\n3  BMI_T2  ~  BMI_T1    b1 0.920 0.011 80.578  0.000    0.898    0.942\n4  BMI_T2  ~ WBIS_T1    h1 0.146 0.047  3.142  0.002    0.055    0.238\n5 WBIS_T3  ~ WBIS_T2    a2 0.846 0.019 45.219  0.000    0.809    0.883\n6 WBIS_T3  ~  BMI_T2    g2 0.010 0.005  2.217  0.027    0.001    0.019\n7  BMI_T3  ~  BMI_T2    b2 0.971 0.011 91.473  0.000    0.951    0.992\n8  BMI_T3  ~ WBIS_T2    h2 0.094 0.043  2.180  0.029    0.010    0.179\n```\n\n\n:::\n:::\n\n\n\n​\n​\n\n*Regression equations*\n\nBased on the unstandardized parameter estimates, the longitudinal dynamics between Weight Bias Internalization (WBIS) and Body Mass Index (BMI) are defined by the following regression equations.\n\n*Wave 2 Predictions:*\n\n$$WBIS\\_T2 = 0.388 + 0.820 \\cdot WBIS\\_{T1} + 0.011 \\cdot BMI\\_{T1}$$\n\n\n$$BMI\\_{T2} = 1.867 + 0.920 \\cdot BMI\\_{T1} + 0.146 \\cdot WBIS\\_{T1}$$\n\n\n*Wave 3 Predictions:*\n\n$$WBIS\\_{T3} = 0.268 + 0.846 \\cdot WBIS\\_{T2} + 0.010 \\cdot BMI\\_{T2}$$\n\n\n$$BMI\\_{T3} = 0.615 + 0.971 \\cdot BMI\\_{T2} + 0.094 \\cdot WBIS\\_{T2}$$\n\n\n​\n\nNow, let's interpret the BMI Wave 3 Prediction:\n\n$$BMI\\_{T3} = 0.615 + 0.971 \\cdot BMI\\_{T2} + 0.094 \\cdot WBIS\\_{T2}$$\n\nThe intercept is the constant or the \"starting value\" for $BMI_{T3}$ when all other predictors in the equation are zero. It is the base level for BMI at Wave 3.\n\nStability ($b_2 = 0.971$): For every 1-unit increase in BMI at Wave 2, BMI at Wave 3 is predicted to increase by 0.971 units, adjusting for Weight Bias Internalization at wave 2.\n\n\nCross-lag ($h_2 = 0.094$): This is the most important coefficient for testing our theoretical model, as it represents the effect of one variable on a different variable over time. For every 1-unit increase in the Weight Bias Internalization Scale (WBIS) at Wave 2, BMI at Wave 3 is predicted to increase by 0.094 units, adjusting the previous BMI.\n\n​\n\n**Indirect effects**\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Pull only the indirect effects you defined at the bottom of your syntax\nsubset(estimates, op == \":=\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           lhs op   rhs       label   est    se      z pvalue ci.lower ci.upper\n24 wb1_wb2_bm3 := a1*h2 wb1_wb2_bm3 0.077 0.036  2.177  0.029    0.008    0.147\n25 wb1_bm2_bm3 := h1*b2 wb1_bm2_bm3 0.142 0.045  3.140  0.002    0.053    0.231\n26 wb1_bm2_wb3 := h1*g2 wb1_bm2_wb3 0.001 0.001  1.811  0.070    0.000    0.003\n27 bm1_wb2_wb3 := g1*a2 bm1_wb2_wb3 0.009 0.004  2.473  0.013    0.002    0.017\n28 bm1_bm2_wb3 := b1*g2 bm1_bm2_wb3 0.009 0.004  2.216  0.027    0.001    0.018\n29 bm1_wb2_bm3 := g1*h2 bm1_wb2_bm3 0.001 0.001  1.636  0.102    0.000    0.002\n30 wb1_wb2_wb3 := a1*a2 wb1_wb2_wb3 0.693 0.022 31.665  0.000    0.650    0.736\n31 bm1_bm2_bm3 := b1*b2 bm1_bm2_bm3 0.894 0.015 60.464  0.000    0.865    0.923\n```\n\n\n:::\n:::\n\n\n\nAll four indirect effects are statistically significant (p<0.05).\n\n\n​\n\n\n## Path diagram\n\nIn Structural Equation Modeling (SEM) frmamwork and path analysis, a graph—often called a path diagram—is not just an illustration; it is a mathematical map of the theory. Using the **_tidySEM_** and **_lavaan_** package in R allows us to translate these mathematical theories into informative visualizations. We will visualize both unstandardized and standardized coefficients.\n\n\n**Graph with Unstandardized Coefficients**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# --- Visualization with tidySEM: Unstandardized estimates ---\n\n# Define the spatial layout\nlay <- get_layout(\n  \"WBIS_T1\", \"WBIS_T2\", \"WBIS_T3\",\n  \"BMI_T1\",  \"BMI_T2\",  \"BMI_T3\", \n  rows = 2\n)\n\n# --- PREPARE GRAPH DATA ---\nres <- table_results(fit, standardized = FALSE)\ngraph_data <- prepare_graph(fit, layout = lay, results = res)\n\n# --- GET RAW P-VALUES FROM SEM() ---\n# Align lavaan terminology (lhs/rhs) with tidySEM terminology (from/to)\nraw_pvals <- parameterEstimates(fit) %>%\n  filter(op == \"~\" | op == \"~~\") %>%\n  mutate(from = ifelse(op == \"~\", rhs, lhs),\n         to = ifelse(op == \"~\", lhs, rhs)) %>%\n  select(from, to, op, p_raw = pvalue)\n\n# --- FORMAT EDGES ---\ngraph_data$edges <- graph_data$edges %>%\n  left_join(raw_pvals, by = c(\"from\", \"to\", \"op\")) %>%\n  mutate(\n    # Recalculate stars based on precise p_raw\n    new_stars = case_when(\n      from == to ~ \"\",                    # No stars for variances\n      is.na(p_raw) ~ \"\",                  # Fallback for paths not found\n      p_raw < 0.001 ~ \"***\",\n      p_raw < 0.01  ~ \"**\",\n      p_raw < 0.05  ~ \"*\",                # 0.013 correctly hits here\n      TRUE          ~ \"\"\n    ),\n    \n    # Check significance for styling\n    is_sig = !is.na(p_raw) & p_raw < 0.05,\n    is_cov = !is.na(curvature) & curvature != 0,\n    is_variance = from == to,\n    \n    # LABEL: Use Rounded Est + Correct Stars for paths; only Est for variances\n    label = ifelse(is_variance, \n                   round(as.numeric(est), 2), \n                   paste0(round(as.numeric(est), 3), new_stars)),\n    \n    # STYLE: Colors based on precise p-value\n    color = ifelse(is_sig | is_variance, \"black\", \"grey75\"),\n    linewidth = 0.5,\n    linetype = ifelse(is_cov, 2, 1)\n  )\n\n# --- NODE LABELING LOGIC (Unchanged) ---\nintercept_table <- parameterEstimates(fit) |> filter(op == \"~1\")\nint_lookup <- setNames(intercept_table$est, intercept_table$lhs)\nr2_values <- inspect(fit, \"rsquare\")\n\ngraph_data$nodes <- graph_data$nodes |> \n  mutate(\n    node_width = 1.8, node_height = 1.2,\n    label = sapply(name, function(x) {\n      val_est <- if(x %in% names(int_lookup)) round(int_lookup[x], 2) else NA\n      if (is.na(val_est)) return(gsub(\"_\", \" \", x))\n      if (grepl(\"T1\", x)) {\n        paste0(gsub(\"_\", \" \", x), \"\\nMean: \", val_est)\n      } else {\n        val_r2 <- if(x %in% names(r2_values)) round(r2_values[x], 2) else 0\n        paste0(gsub(\"_\", \" \", x), \"\\nInt: \", val_est, \"\\nR²: \", val_r2)\n      }\n    })\n  )\n\n# --- FINAL PLOT ---\nplot(graph_data) + \n  labs(\n    title = \"Unstandardized Regression Coefficients\",\n    subtitle = \"Significant paths highlighted with asterisks\n    (*p < .05, **p < .01, ***p < .001)\",\n    caption = \"Solid lines = Regressions; Dashed lines = Covariances; \n    Circles = Variances.\"\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n\n​\n\n**Graph with Standardized Coefficients**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Prepare the graph data\ngraph_data_std <- prepare_graph(fit, layout = lay, standardized = TRUE)\n\n# Get high-precision p-values from lavaan\n# IMPORTANT: In lavaan Y ~ X, lhs is Y (to) and rhs is X (from).\nraw_pvals <- parameterEstimates(fit) |>\n  filter(op == \"~\" | op == \"~~\") |> \n  mutate(from = ifelse(op == \"~\", rhs, lhs),\n         to = ifelse(op == \"~\", lhs, rhs)) |>\n  select(from, to, p_raw = pvalue)\n\n# Merge and create the label\ngraph_data_std$edges <- graph_data_std$edges |>\n  left_join(raw_pvals, by = c(\"from\", \"to\")) |>\n  mutate(\n    # Create the stars based on the high-precision p_raw\n    new_stars = case_when(\n      from == to ~ \"\",                    # No stars for variances\n      is.na(p_raw) ~ \"\",                  # Handle missing p-values\n      p_raw < 0.001 ~ \"***\",\n      p_raw < 0.01  ~ \"**\",\n      p_raw < 0.05  ~ \"*\",                # 0.013 will correctly get one *\n      TRUE          ~ \"\"\n    ),\n    # Overwrite the label with rounded estimate + our precise stars\n    label = paste0(round(as.numeric(est_std), 2), new_stars)\n  )\n\n# Standard Node Formatting\ngraph_data_std$nodes <- graph_data_std$nodes |> \n  mutate(\n    node_width = 1.5, node_height = 1.0,\n    label = sapply(name, function(x) {\n      clean_name <- gsub(\"_\", \" \", x)\n      if (grepl(\"T1\", x)) return(clean_name)\n      val_r2 <- if(x %in% names(r2_values)) round(r2_values[x], 2) else 0\n      paste0(clean_name, \"\\nR²: \", val_r2)\n    })\n  )\n\n# Plot\nplot(graph_data_std) + \nlabs(\n    title = \"Standardized Regression Coefficients\",\n    subtitle = \"Significant paths highlighted with asterisks\n    (*p < .05, **p < .01, ***p < .001)\",\n    caption = \"Solid lines = Regressions; Dashed lines = Covariances; \n    Circles = Variances.\"\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}